# -*- coding: utf-8 -*-
"""
å¤šéº¦å…‹é£éŸ³é¢‘æ¥å£é©±åŠ¨ï¼ˆåŸºäºæ ˆå¼/é˜Ÿåˆ—ç¼“å­˜ï¼‰
ä¿ç•™æœ€è¿‘å›ºå®šæ—¶é•¿ï¼ˆé»˜è®¤5ç§’ï¼‰çš„éŸ³é¢‘å¸§ï¼Œå¹¶æä¾›ä¾¿æ·çš„è¯»å–æ¥å£ã€‚
"""

import pyaudio
import numpy as np
import threading
import time
from collections import deque

class MultiMicAudioInterface:
    def __init__(self, device_index=None, sample_rate=44100, channels=2, chunk_size=1024, sample_format: str = "auto"):
        """
        åˆå§‹åŒ–éŸ³é¢‘æ¥å£
        
        Args:
            device_index: éŸ³é¢‘è®¾å¤‡ç´¢å¼•ï¼ŒNoneä¸ºé»˜è®¤è®¾å¤‡
            sample_rate: é‡‡æ ·ç‡ï¼Œé»˜è®¤44100Hz
            channels: é€šé“æ•°ï¼Œé»˜è®¤2ï¼ˆç«‹ä½“å£°ï¼‰
            chunk_size: éŸ³é¢‘å—å¤§å°ï¼Œé»˜è®¤1024
            sample_format: é‡‡æ ·æ ¼å¼ï¼Œå¯é€‰ "auto" | "int24" | "int16" | "float32"ï¼Œé»˜è®¤è‡ªåŠ¨ä¼˜å…ˆå°è¯•24ä½
        """
        self.sample_rate = sample_rate
        self.channels = channels
        self.chunk_size = chunk_size
        self.sample_format_name = (sample_format or "auto").lower()
        self._pa_format = None  # å®é™…æ‰“å¼€æˆåŠŸçš„PortAudioæ ¼å¼
        self._sample_width = None  # æ¯æ ·æœ¬å­—èŠ‚æ•°
        # è¾“å…¥æ•°æ®è½¬æ¢å‡½æ•°ï¼Œè¿”å›float32ä¸”å½¢çŠ¶ä¸º (channels, frames)
        self._convert_input = None
        
        # æ§åˆ¶çº¿ç¨‹è¿è¡Œ
        self.is_running = False
        
        # éŸ³é¢‘é˜Ÿåˆ—åŠŸèƒ½ - ä¿å­˜5ç§’çš„éŸ³é¢‘æ•°æ®
        self.queue_duration = 5.0  # 5ç§’
        self.queue_max_frames = int(self.sample_rate * self.queue_duration / self.chunk_size)
        self.audio_queue = deque(maxlen=self.queue_max_frames)  # ä½¿ç”¨dequeå®ç°æ ˆå¼å­˜å‚¨
        self.queue_timestamps = deque(maxlen=self.queue_max_frames)  # å¯¹åº”çš„æ—¶é—´æˆ³
        self.queue_lock = threading.Lock()
        # æ–°æ•°æ®äº‹ä»¶ï¼šæœ‰æ–°å¸§å†™å…¥æ—¶è§¦å‘ï¼Œä¾¿äºé˜»å¡ç­‰å¾…æœ€æ–°å¸§
        self.new_frame_event = threading.Event()
        
        # Initialize PyAudio
        self.pyaudio = pyaudio.PyAudio()

        # æ‰“å¼€è¾“å…¥æµï¼ˆæ”¯æŒè‡ªåŠ¨/æŒ‡å®šé‡‡æ ·æ ¼å¼ï¼‰
        self.stream = self._open_stream_with_preferred_format(device_index)

    # ---------------- å†…éƒ¨ï¼šæ‰“å¼€æµä¸æ ¼å¼è§£æ ----------------
    def _open_stream_with_preferred_format(self, device_index):
        """æ ¹æ®æœŸæœ›æ ¼å¼å°è¯•æ‰“å¼€è¾“å…¥æµï¼Œå¹¶è®¾ç½®å¯¹åº”çš„è§£æå‡½æ•°ã€‚"""
        # ä¼˜å…ˆçº§ï¼šint24 -> float32 -> int16ï¼ˆè‹¥ä¸ºautoï¼‰
        name2fmt = {
            "int24": pyaudio.paInt24,
            "int16": pyaudio.paInt16,
            "float32": pyaudio.paFloat32,
        }

        if self.sample_format_name == "auto":
            candidates = ["int24", "float32", "int16"]
        else:
            if self.sample_format_name not in name2fmt:
                raise ValueError(f"ä¸æ”¯æŒçš„sample_format: {self.sample_format_name}")
            candidates = [self.sample_format_name]

        last_err = None
        for name in candidates:
            pa_fmt = name2fmt[name]
            try:
                stream = self.pyaudio.open(
                    format=pa_fmt,
                    channels=self.channels,
                    rate=self.sample_rate,
                    input=True,
                    input_device_index=device_index,
                    frames_per_buffer=self.chunk_size,
                    stream_callback=self._audio_callback
                )
                # æˆåŠŸï¼šè®°å½•æ ¼å¼ã€æ ·å®½ä¸è½¬æ¢å™¨
                self._pa_format = pa_fmt
                self.sample_format_name = name
                self._sample_width = self.pyaudio.get_sample_size(pa_fmt)
                if name == "int24":
                    self._convert_input = self._convert_int24_to_float32
                elif name == "int16":
                    self._convert_input = self._convert_int16_to_float32
                elif name == "float32":
                    self._convert_input = self._convert_float32_to_float32
                print(f"ğŸ§ è¾“å…¥æµå·²æ‰“å¼€ï¼Œé‡‡æ ·æ ¼å¼: {name}ï¼ˆ{self._sample_width*8}ä½ï¼‰")
                return stream
            except Exception as e:
                last_err = e
                continue

        # å…¨éƒ¨å¤±è´¥
        raise RuntimeError(f"æ— æ³•æ‰“å¼€è¾“å…¥æµï¼Œå°è¯•çš„æ ¼å¼: {candidates}ï¼Œæœ€åé”™è¯¯: {last_err}")

    def _convert_int16_to_float32(self, in_data, frame_count):
        audio = np.frombuffer(in_data, dtype=np.int16)
        audio = audio.reshape((frame_count, self.channels)).T
        return (audio.astype(np.float32) / 32768.0)

    def _convert_float32_to_float32(self, in_data, frame_count):
        audio = np.frombuffer(in_data, dtype=np.float32)
        audio = audio.reshape((frame_count, self.channels)).T
        return audio

    def _convert_int24_to_float32(self, in_data, frame_count):
        # 24bit PCM â†’ int32 æœ‰ç¬¦å·ï¼Œå†å½’ä¸€åŒ–åˆ°[-1,1)
        b = np.frombuffer(in_data, dtype=np.uint8)
        expected = frame_count * self.channels * 3
        if b.size != expected:
            # å°ºå¯¸å¼‚å¸¸ï¼Œå°½é‡åœ¨ä¸å´©æºƒçš„æƒ…å†µä¸‹è¿”å›ç©º
            print(f"è­¦å‘Šï¼šæ¥æ”¶å­—èŠ‚æ•°ä¸24ä½æœŸæœ›ä¸ç¬¦: got={b.size}, expected={expected}")
            return np.zeros((self.channels, frame_count), dtype=np.float32)
        b = b.reshape(-1, 3)
        # little-endian: LSB, mid, MSB
        val = (b[:, 0].astype(np.int32) |
               (b[:, 1].astype(np.int32) << 8) |
               (b[:, 2].astype(np.int32) << 16))
        # ç¬¦å·æ‰©å±•ï¼ˆ24bitï¼‰
        neg = (val & 0x800000) != 0
        val[neg] -= (1 << 24)
        # å½’ä¸€åŒ–
        audio = (val.astype(np.float32) / 8388608.0)  # 2^23
        audio = audio.reshape((frame_count, self.channels)).T
        return audio

    def _audio_callback(self, in_data, frame_count, time_info, status):
        """PyAudio å›è°ƒå‡½æ•°ï¼Œåœ¨éŸ³é¢‘çº¿ç¨‹ä¸­è‡ªåŠ¨è°ƒç”¨"""
        try:
            # å°†å›è°ƒè¾“å…¥è½¬æ¢ä¸º float32, å½¢çŠ¶ (channels, frame_count)
            if self._convert_input is None:
                # ç†è®ºä¸Šä¸åº”å‘ç”Ÿ
                print("é”™è¯¯ï¼šæœªåˆå§‹åŒ–çš„è¾“å…¥è½¬æ¢å™¨")
                return (None, pyaudio.paAbort)
            audio_data = self._convert_input(in_data, frame_count)
            
            # ç¡®ä¿æ•°æ®å¤§å°åŒ¹é…ç¼“å†²åŒº
            if audio_data.shape[1] == self.chunk_size:
                # è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆä½¿ç”¨é«˜ç²¾åº¦æ—¶é—´ï¼‰
                current_timestamp = time.time()
                # æ›´æ–°éŸ³é¢‘é˜Ÿåˆ—ï¼ˆæ ˆå¼å­˜å‚¨æœ€æ–°æ•°æ®ï¼‰
                with self.queue_lock:
                    self.audio_queue.append(audio_data.copy())  # æ·»åŠ åˆ°é˜Ÿåˆ—æœ«å°¾ï¼ˆæœ€æ–°æ•°æ®ï¼‰
                    self.queue_timestamps.append(current_timestamp)
                    # dequeä¼šè‡ªåŠ¨åˆ é™¤è¶…å‡ºmaxlençš„æ—§æ•°æ®
                # é€šçŸ¥æœ‰æ–°å¸§åˆ°è¾¾
                self.new_frame_event.set()
                    
            else:
                print(f"è­¦å‘Šï¼šéŸ³é¢‘å¸§å¤§å°ä¸åŒ¹é… {audio_data.shape} vs expected ({self.channels}, {self.chunk_size})")
                
        except Exception as e:
            print(f"éŸ³é¢‘å›è°ƒé”™è¯¯: {e}")
            
        return (None, pyaudio.paContinue)

    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if not self.is_running:
            self.is_running = True
            self.stream.start_stream()

    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if self.is_running:
            self.is_running = False
            self.stream.stop_stream()

    def wait_for_next_frame(self, timeout: float = 1.0):
        """
        é˜»å¡ç­‰å¾…ä¸‹ä¸€å¸§çš„åˆ°æ¥ï¼Œå¹¶è¿”å›æœ€æ–°å¸§åŠå…¶æ—¶é—´æˆ³ã€‚
        å¦‚æœåœ¨è¶…æ—¶æ—¶é—´å†…æ²¡æœ‰æ–°å¸§ï¼Œåˆ™è¿”å› (None, None)ã€‚
        """
        # å¿«é€Ÿæ¸…é™¤ä¸Šä¸€æ¬¡çš„äº‹ä»¶ï¼ˆé¿å…æ—§äº‹ä»¶é€ æˆè¯¯åˆ¤ï¼‰
        self.new_frame_event.clear()
        if not self.new_frame_event.wait(timeout):
            return None, None
        return self.read_queue_latest_frame()
    
    def read_queue_latest_frame(self):
        """
        ä»é˜Ÿåˆ—ä¸­è¯»å–æœ€æ–°çš„ä¸€å¸§éŸ³é¢‘æ•°æ®
        
        Returns:
            tuple: (audio_data, timestamp) æˆ– (None, None)
                audio_data: éŸ³é¢‘æ•°æ® (channels, samples)
                timestamp: è¯¥å¸§çš„æ—¶é—´æˆ³
        """
        # ä»…åœ¨é”å†…è·å–å¼•ç”¨ï¼Œå¤åˆ¶åœ¨é”å¤–å®Œæˆï¼Œé¿å…é˜»å¡å›è°ƒçº¿ç¨‹
        with self.queue_lock:
            if len(self.audio_queue) == 0:
                return None, None
            latest_ref = self.audio_queue[-1]
            latest_timestamp = self.queue_timestamps[-1]
        # åœ¨é”å¤–å¤åˆ¶æ•°æ®
        return latest_ref.copy(), latest_timestamp
    
    def read_queue_all_frames(self):
        """
        ä»é˜Ÿåˆ—ä¸­è¯»å–æ‰€æœ‰éŸ³é¢‘å¸§ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼Œæœ€æ—§åˆ°æœ€æ–°ï¼‰
        
        Returns:
            tuple: (frames_list, timestamps_list) æˆ– ([], [])
                frames_list: éŸ³é¢‘å¸§åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (channels, samples)
                timestamps_list: å¯¹åº”çš„æ—¶é—´æˆ³åˆ—è¡¨
        """
        # é”å†…åšå¿«ç…§ï¼Œé”å¤–åšå¤åˆ¶ï¼Œç¼©çŸ­åŠ é”æ—¶é—´
        with self.queue_lock:
            if len(self.audio_queue) == 0:
                return [], []
            frames_snapshot = list(self.audio_queue)
            timestamps = list(self.queue_timestamps)
        frames = [frame.copy() for frame in frames_snapshot]
        return frames, timestamps
    
    def read_queue_duration(self, duration):
        """
        ä»é˜Ÿåˆ—ä¸­è¯»å–æŒ‡å®šæ—¶é•¿çš„æœ€æ–°éŸ³é¢‘æ•°æ®
        
        Args:
            duration: éœ€è¦è¯»å–çš„æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œæœ€å¤§5ç§’
            
        Returns:
            tuple: (audio_data, start_timestamp, end_timestamp) æˆ– (None, None, None)
                audio_data: æ‹¼æ¥åçš„éŸ³é¢‘æ•°æ® (channels, total_samples)
                start_timestamp: ç¬¬ä¸€å¸§æ—¶é—´æˆ³
                end_timestamp: æœ€åä¸€å¸§æ—¶é—´æˆ³
        """
        duration = min(duration, self.queue_duration)  # é™åˆ¶æœ€å¤§æ—¶é•¿
        needed_frames = int(duration * self.sample_rate / self.chunk_size)
        # é”å†…ä»…è®¡ç®—åŒºé—´å¹¶åšå¿«ç…§ï¼Œé”å¤–æ‰§è¡Œè€—æ—¶æ‹¼æ¥
        with self.queue_lock:
            qlen = len(self.audio_queue)
            if qlen == 0:
                return None, None, None
            actual_frames = min(needed_frames, qlen)
            start_idx = qlen - actual_frames
            frames_snapshot = list(self.audio_queue)[start_idx:]
            timestamps_snapshot = list(self.queue_timestamps)[start_idx:]
        if not frames_snapshot:
            return None, None, None
        concatenated_audio = np.concatenate(frames_snapshot, axis=1)
        start_timestamp = timestamps_snapshot[0]
        end_timestamp = timestamps_snapshot[-1]
        return concatenated_audio, start_timestamp, end_timestamp
    
    def get_queue_status(self):
        """
        è·å–é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯
        
        Returns:
            dict: é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯
                - frame_count: å½“å‰é˜Ÿåˆ—ä¸­çš„å¸§æ•°
                - max_frames: æœ€å¤§å¸§æ•°
                - duration: å½“å‰é˜Ÿåˆ—è¦†ç›–çš„æ—¶é•¿ï¼ˆç§’ï¼‰
                - max_duration: æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰
                - is_full: é˜Ÿåˆ—æ˜¯å¦å·²æ»¡
        """
        with self.queue_lock:
            frame_count = len(self.audio_queue)
            current_duration = frame_count * self.chunk_size / self.sample_rate
            
            return {
                'frame_count': frame_count,
                'max_frames': self.queue_max_frames,
                'duration': current_duration,
                'max_duration': self.queue_duration,
                'is_full': frame_count >= self.queue_max_frames
            }

    def get_queue_time_range(self):
        """
        è·å–å½“å‰ç¼“å­˜ä¸­çš„æ—¶é—´èŒƒå›´ï¼ˆæœ€æ—§æ—¶é—´æˆ³, æœ€æ–°æ—¶é—´æˆ³ï¼‰ã€‚
        è‹¥é˜Ÿåˆ—ä¸ºç©ºï¼Œè¿”å› (None, None)ã€‚
        """
        with self.queue_lock:
            if not self.queue_timestamps:
                return None, None
            return self.queue_timestamps[0], self.queue_timestamps[-1]

    def read_queue_by_time(self, start_timestamp: float, end_timestamp: float):
        """
        æŒ‰æ—¶é—´æˆ³èŒƒå›´è¯»å–ç¼“å­˜ä¸­çš„éŸ³é¢‘æ•°æ®ã€‚
        è¦æ±‚[start_timestamp, end_timestamp]å®Œå…¨è½åœ¨5ç§’å›ºå®šç¼“å­˜èŒƒå›´å†…ï¼Œ
        å¦åˆ™ç›´æ¥æŠ›å‡º ValueErrorã€‚

        è¯´æ˜ï¼š
        - æ¯å¸§çš„æ—¶é—´æˆ³è¡¨ç¤ºè¯¥å¸§ç»“æŸçš„æ—¶é—´ç‚¹ï¼ˆè¿‘ä¼¼PyAudioå›è°ƒåˆ°è¾¾æ—¶é—´ï¼‰ã€‚
        - æœ¬æ–¹æ³•é€‰æ‹©æ»¡è¶³ start < ts <= end çš„æ‰€æœ‰å¸§å¹¶æ‹¼æ¥ï¼Œä¸åšæ ·æœ¬çº§è£å‰ªã€‚

        Args:
            start_timestamp: èµ·å§‹æ—¶é—´æˆ³ï¼ˆUnixç§’ï¼‰
            end_timestamp: æˆªæ­¢æ—¶é—´æˆ³ï¼ˆUnixç§’ï¼‰

        Returns:
            tuple: (audio_data, actual_start_timestamp, actual_end_timestamp)
                audio_data: (channels, total_samples)
                actual_start_timestamp: é€‰ä¸­ç¬¬ä¸€å¸§çš„æ—¶é—´æˆ³
                actual_end_timestamp: é€‰ä¸­æœ€åä¸€å¸§çš„æ—¶é—´æˆ³

        Raises:
            ValueError: å‚æ•°æ— æ•ˆã€é˜Ÿåˆ—ä¸ºç©ºã€è¶…å‡ºç¼“å­˜èŒƒå›´æˆ–èŒƒå›´å†…æ— æ•°æ®
        """
        if start_timestamp is None or end_timestamp is None:
            raise ValueError("start_timestamp å’Œ end_timestamp ä¸èƒ½ä¸ºç©º")
        if end_timestamp <= start_timestamp:
            raise ValueError("end_timestamp å¿…é¡»å¤§äº start_timestamp")

        # é”å†…è·å–æ—¶é—´èŒƒå›´ä¸å¿«ç…§
        with self.queue_lock:
            qlen = len(self.queue_timestamps)
            if qlen == 0:
                raise ValueError("éŸ³é¢‘ç¼“å­˜ä¸ºç©º")

            oldest = self.queue_timestamps[0]
            newest = self.queue_timestamps[-1]

            # è¾¹ç•Œæ£€æŸ¥ï¼šå®Œæ•´è½å…¥å½“å‰5ç§’ç¼“å­˜çª—å£
            if start_timestamp < oldest or end_timestamp > newest:
                raise ValueError(
                    f"è¯·æ±‚çš„æ—¶é—´èŒƒå›´è¶…å‡ºç¼“å­˜çª—å£: è¯·æ±‚[{start_timestamp:.3f}, {end_timestamp:.3f}], ç¼“å­˜[{oldest:.3f}, {newest:.3f}]"
                )

            # åšå¿«ç…§ä»¥ç¼©çŸ­æŒé”
            ts_snapshot = list(self.queue_timestamps)
            frames_snapshot = list(self.audio_queue)

        # é”å¤–æŸ¥æ‰¾æ»¡è¶³ start < ts <= end çš„å¸§ç´¢å¼•åŒºé—´
        sel_idx = [i for i, ts in enumerate(ts_snapshot) if (ts > start_timestamp and ts <= end_timestamp)]
        if not sel_idx:
            raise ValueError("æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰å¯ç”¨çš„éŸ³é¢‘å¸§")

        first_i, last_i = sel_idx[0], sel_idx[-1]
        selected_frames = frames_snapshot[first_i:last_i + 1]
        selected_timestamps = ts_snapshot[first_i:last_i + 1]

        # æ‹¼æ¥éŸ³é¢‘ï¼ˆé”å¤–ï¼‰
        audio = np.concatenate(selected_frames, axis=1)
        return audio, selected_timestamps[0], selected_timestamps[-1]
    
    def clear_queue(self):
        """æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—"""
        with self.queue_lock:
            self.audio_queue.clear()
            self.queue_timestamps.clear()

    def close(self):
        """å…³é—­éŸ³é¢‘æ¥å£"""
        self.stop_recording()
        if self.stream:
            self.stream.close()
        self.pyaudio.terminate()

    def __enter__(self):
        """æ”¯æŒ with è¯­å¥"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """æ”¯æŒ with è¯­å¥"""
        self.close()