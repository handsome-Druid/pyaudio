# -*- coding: utf-8 -*-
"""
ä¸¥æ ¼è¯»å–æœ€å4ç§’éŸ³é¢‘çš„è„šæœ¬
- ä½¿ç”¨ä¸¥æ ¼æ¥å£ read_queue_by_time() ä»…è·å–æœ€å4ç§’æ•°æ®
- æ¯æ¬¡è¯»å–åç­‰å¾…4ç§’å†è¯»
- æ”¯æŒé€šè¿‡å‚æ•°æŒ‡å®šå¾ªç¯æ¬¡æ•°ã€è®¾å¤‡ç´¢å¼•ã€é€šé“æ•°

ç”¨æ³•ç¤ºä¾‹ï¼š
    python strict_last4_reader.py --iterations 3 --device-index 0 --channels 2
"""

import argparse
import time
from datetime import datetime
import numpy as np
import wave
from pathlib import Path

from audio_interface import MultiMicAudioInterface


def db_from_rms(x: float) -> float:
    return float(20 * np.log10(max(x, 1e-10)))


essay = """
è¯´æ˜ï¼š
- æœ¬è„šæœ¬ä½¿ç”¨ä¸¥æ ¼çš„æŒ‰æ—¶é—´æˆ³è¯»å–æ¥å£ read_queue_by_time(start_ts, end_ts)ã€‚
- å¦‚æœç¼“å­˜ä¸è¶³4ç§’ï¼ˆä¾‹å¦‚å¯åŠ¨åˆæœŸï¼‰ï¼Œä¸¥æ ¼æ¥å£ä¼šæŠ¥é”™ï¼›è„šæœ¬ä¼šç­‰å¾…ç›´è‡³è¶³å¤Ÿæ•°æ®åå†å¼€å§‹å¾ªç¯ã€‚
- æ¯æ¬¡å¾ªç¯ï¼š
  1) è·å–å½“å‰ç¼“å­˜æ—¶é—´èŒƒå›´ (oldest, newest)
  2) ä½¿ç”¨ [newest-4.0, newest] ä½œä¸ºä¸¥æ ¼è¯»å–åŒºé—´
  3) æ‰“å°æœ¬æ¬¡è¯»å–çš„åŸºæœ¬ç»Ÿè®¡ï¼ˆå½¢çŠ¶ã€æ—¶é•¿ã€RMSç­‰ï¼‰
  4) ç­‰å¾…4ç§’è¿›å…¥ä¸‹ä¸€è½®
"""


def parse_args():
    p = argparse.ArgumentParser(description="ä¸¥æ ¼è¯»å–æœ€å4ç§’éŸ³é¢‘æ•°æ®")
    p.add_argument("--iterations", type=int, default=3, help="å¾ªç¯æ¬¡æ•°ï¼Œé»˜è®¤3")
    p.add_argument("--device-index", type=int, default=None, help="éŸ³é¢‘è®¾å¤‡ç´¢å¼•ï¼Œé»˜è®¤None=ç³»ç»Ÿé»˜è®¤è®¾å¤‡")
    p.add_argument("--channels", type=int, default=2, help="é€šé“æ•°ï¼Œé»˜è®¤2")
    p.add_argument("--sample-rate", type=int, default=44100, help="é‡‡æ ·ç‡ï¼Œé»˜è®¤44100")
    p.add_argument("--chunk-size", type=int, default=1024, help="å—å¤§å°ï¼ˆå¸§æ•°ï¼‰ï¼Œé»˜è®¤1024")
    p.add_argument("--sample-format", type=str, default="auto", choices=["auto", "int24", "int16", "float32"], help="é‡‡æ ·æ ¼å¼ï¼Œé»˜è®¤autoä¼˜å…ˆå°è¯•24ä½")
    p.add_argument("--output", type=str, default=None, help="è¾“å‡ºWAVæ–‡ä»¶åï¼›æœªæŒ‡å®šæ—¶è‡ªåŠ¨ç”Ÿæˆ")
    return p.parse_args()


def wait_until_enough_buffer(audio: MultiMicAudioInterface, need_seconds: float = 4.0, timeout: float = 15.0) -> bool:
    """ç­‰å¾…ç¼“å­˜è¾¾åˆ°æŒ‡å®šç§’æ•°ï¼›è¶…æ—¶è¿”å›False"""
    deadline = time.time() + timeout
    last_report = 0
    while time.time() < deadline:
        oldest, newest = audio.get_queue_time_range()
        if oldest is not None and newest is not None:
            if (newest - oldest) >= need_seconds:
                return True
            # æ¯500msæŠ¥å‘Šä¸€æ¬¡å½“å‰è¿›åº¦
            now = time.time()
            if now - last_report > 0.5:
                have = newest - oldest
                print(f"ğŸ•’ ç­‰å¾…ç¼“å­˜å¡«å……ï¼šå½“å‰â‰ˆ{have:.2f}s / ç›®æ ‡ {need_seconds:.2f}s", end="\r", flush=True)
                last_report = now
        time.sleep(0.05)
    return False


def strict_read_last4(audio: MultiMicAudioInterface):
    """ä¸¥æ ¼è¯»å–æœ€å4ç§’ï¼Œè¿”å› (data, t0, t1)ï¼›è‹¥å› ç«äº‰å¤±è´¥ï¼Œå°è¯•å°æ¬¡æ•°å¿«é€Ÿé‡è¯•"""
    # å°é‡è¯•å¯ä»¥ç¼“è§£ newest å˜åŒ–å¯¼è‡´çš„è¾¹ç•Œç«äº‰
    for _ in range(3):
        oldest, newest = audio.get_queue_time_range()
        if oldest is None or newest is None:
            raise ValueError("ç¼“å­˜ä¸ºç©º")
        start_ts = newest - 4.0
        end_ts = newest
        try:
            data, t0, t1 = audio.read_queue_by_time(start_ts, end_ts)
            return data, t0, t1
        except ValueError:
            time.sleep(0.02)
    # æœ€ç»ˆå¤±è´¥åˆ™æŠ›å‡º
    data, t0, t1 = audio.read_queue_by_time(newest - 4.0, newest)
    return data, t0, t1


def main():
    args = parse_args()
    print("=" * 60)
    print("ğŸ¯ ä¸¥æ ¼è¯»å–æœ€å4ç§’éŸ³é¢‘")
    print("=" * 60)
    print(essay)

    with MultiMicAudioInterface(
        device_index=args.device_index,
        sample_rate=args.sample_rate,
        channels=args.channels,
        chunk_size=args.chunk_size,
        sample_format=args.sample_format,
    ) as audio:
        audio.start_recording()
        print("ğŸ™ï¸  å·²å¼€å§‹å½•éŸ³ã€‚")

        # å¯åŠ¨æœŸï¼šç­‰å¾…ç¼“å­˜è‡³å°‘è¾¾åˆ°4ç§’
        print("â³ æ­£åœ¨ç­‰å¾…ç¼“å­˜å¡«å……è‡³ 4.0 ç§’â€¦â€¦")
        if not wait_until_enough_buffer(audio, need_seconds=4.0, timeout=30.0):
            print("âŒ åœ¨è¶…æ—¶æ—¶é—´å†…ç¼“å­˜ä¸è¶³4ç§’ï¼Œé€€å‡ºã€‚")
            return
        print("\nâœ… ç¼“å­˜æ»¡è¶³æ¡ä»¶ï¼Œå¼€å§‹ä¸¥æ ¼è¯»å–å¾ªç¯ã€‚\n")

        collected = []  # æ”¶é›†æ¯æ¬¡è¯»å–åˆ°çš„4ç§’æ•°æ® (channels, samples)
        time_ranges = []  # æ”¶é›†æ¯æ¬¡çš„æ—¶é—´èŒƒå›´ (t0, t1)

        for i in range(1, args.iterations + 1):
            print(f"â€”â€” ç¬¬ {i}/{args.iterations} æ¬¡ â€”â€”")
            try:
                data, t0, t1 = strict_read_last4(audio)
            except ValueError as e:
                print(f"âŒ è¯»å–å¤±è´¥: {e}")
                break

            # åŸºæœ¬ä¿¡æ¯
            duration = data.shape[1] / audio.sample_rate
            print(f"æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(t0).strftime('%H:%M:%S.%f')[:-3]} ~ {datetime.fromtimestamp(t1).strftime('%H:%M:%S.%f')[:-3]}")
            print(f"æ•°æ®å½¢çŠ¶: {tuple(data.shape)} | å®é™…æ—¶é•¿: {duration:.2f}s")

            # ç®€å•ç”µå¹³åˆ†æ
            for ch in range(data.shape[0]):
                rms = float(np.sqrt(np.mean(data[ch] ** 2)))
                print(f"  é€šé“{ch}: RMS={db_from_rms(rms):6.1f} dB")

            # ä¿å­˜æœ¬æ¬¡ç»“æœä»¥ä¾¿æœ€ç»ˆæ‹¼æ¥
            collected.append(data)
            time_ranges.append((t0, t1))

            if i < args.iterations:
                print("â³ ç­‰å¾… 4 ç§’è¿›å…¥ä¸‹ä¸€è½®â€¦â€¦\n")
                time.sleep(4.0)

        # å¾ªç¯ç»“æŸåï¼Œå°†æ‰€æœ‰ç‰‡æ®µæ‹¼æ¥å¹¶å†™å…¥WAV
        if collected:
            full = np.concatenate(collected, axis=1)  # (channels, total_samples)

            # ç”Ÿæˆæ–‡ä»¶å
            if args.output:
                out_path = Path(args.output)
            else:
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                out_name = f"strict_last4_concat_{ts}_sr{audio.sample_rate}_ch{audio.channels}_n{len(collected)}.wav"
                out_path = Path(out_name)

            # å†™WAVï¼ˆæ ¹æ®å®é™…è¾“å…¥æ ¼å¼é€‰æ‹©ä½æ·±ï¼›æ”¯æŒint24/ int16ï¼‰
            with wave.open(str(out_path), 'wb') as wf:
                wf.setnchannels(audio.channels)
                wf.setframerate(audio.sample_rate)
                interleaved_f = np.clip(full.T, -1.0, 1.0)
                if getattr(audio, "sample_format_name", "int16") == "int24":
                    # 24ä½å†™å…¥
                    wf.setsampwidth(3)
                    # float32 -> int24 little-endian bytes
                    x = np.round(np.clip(interleaved_f * 8388608.0, -8388608, 8388607)).astype(np.int32)
                    b0 = (x & 0xFF).astype(np.uint8)
                    b1 = ((x >> 8) & 0xFF).astype(np.uint8)
                    b2 = ((x >> 16) & 0xFF).astype(np.uint8)
                    packed = np.stack([b0, b1, b2], axis=-1).reshape(-1)
                    wf.writeframes(packed.tobytes())
                else:
                    # é»˜è®¤16ä½
                    wf.setsampwidth(2)
                    interleaved_i16 = (interleaved_f * 32767.0).astype(np.int16)  # (samples, channels)
                    wf.writeframes(interleaved_i16.tobytes())

            total_sec = full.shape[1] / audio.sample_rate
            tr0, tr1 = time_ranges[0][0], time_ranges[-1][1]
            print("\nğŸ’¾ å·²ä¿å­˜æ‹¼æ¥WAV:")
            print(f"  æ–‡ä»¶: {out_path.resolve()}")
            print(f"  æ€»æ—¶é•¿: {total_sec:.2f}s | ç‰‡æ®µæ•°: {len(collected)}")
            print(f"  è¦†ç›–æ—¶é—´: {datetime.fromtimestamp(tr0).strftime('%H:%M:%S.%f')[:-3]} ~ {datetime.fromtimestamp(tr1).strftime('%H:%M:%S.%f')[:-3]}")
        else:
            print("\nâš ï¸ æœªæ”¶é›†åˆ°ä»»ä½•æ•°æ®ï¼Œæœªç”ŸæˆWAVæ–‡ä»¶ã€‚")

        print("\nğŸ‰ å®Œæˆã€‚")


if __name__ == "__main__":
    main()
